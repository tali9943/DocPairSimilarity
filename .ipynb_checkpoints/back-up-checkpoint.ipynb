{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b8f64ae4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_PYTHON'] = 'C:/Users/lita4/anaconda3/python.exe'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = 'C:/Users/lita4/anaconda3/python.exe'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7252d169",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_name_documents = './Databases/prova/prova2.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "012fa518",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "# Creazione della sessione Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"MySparkApp\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "\n",
    "\n",
    "def sim(document1, document2):\n",
    "    # Example similarity calculation using cosine similarity\n",
    "    vector1 = np.array(document1)\n",
    "    vector2 = np.array(document2)\n",
    "    dot_product = np.dot(vector1, vector2)\n",
    "    norm1 = np.linalg.norm(vector1)\n",
    "    norm2 = np.linalg.norm(vector2)\n",
    "    similarity = dot_product / (norm1 * norm2)\n",
    "    return similarity\n",
    "\n",
    "\n",
    "\n",
    "def b(document):\n",
    "    # Example function to calculate the threshold 'b' for a document\n",
    "    threshold = np.mean([value for _, value in document])\n",
    "    return threshold\n",
    "\n",
    "\n",
    "\n",
    "# Funzione di mappatura\n",
    "def my_map(doc_id, document):\n",
    "    map_results = []\n",
    "    threshold = b(document)\n",
    "    for term, value in sorted(document):\n",
    "        if value > threshold:\n",
    "            map_results.append((term, (doc_id, document)))\n",
    "    return map_results\n",
    "\n",
    "# Funzione di riduzione\n",
    "def my_reduce(map_results, threshold):\n",
    "    emitted_results = []\n",
    "    for item in map_results:\n",
    "        t = item[0]  # Prendi il primo valore della tupla come t\n",
    "        doc_id, document = item[1]\n",
    "        for id1, d1 in document:\n",
    "            print(id1)\n",
    "            print(d1)\n",
    "            print(document)\n",
    "            for id2, d2 in document:\n",
    "                print(id2+1)\n",
    "                print(d2+1)\n",
    "                if t == max(set(d1.keys()) & set(d2.keys())):\n",
    "                    similarity = sim(list(d1.values()), list(d2.values()))\n",
    "                    if similarity >= threshold:\n",
    "                        emitted_results.append((id1, id2, similarity))\n",
    "    return emitted_results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def my_reduce1(map_results, threshold):\n",
    "    emitted_results = []\n",
    "    for item in map_results.collect():\n",
    "        t = item[0]\n",
    "        doc_id, document = item[1]\n",
    "        for index, (id1, d1) in enumerate(document):\n",
    "            if index + 1 < len(document):\n",
    "                id2, d2 = document[index + 1]\n",
    "                if isinstance(d1, dict) and isinstance(d2, dict):  # Check if d1 and d2 are dictionaries\n",
    "                    if t == max(set(d1.keys()) & set(d2.keys())):\n",
    "                        similarity = sim(list(d1.values()), list(d2.values()))\n",
    "                        if similarity >= threshold:\n",
    "                            emitted_results.append((id1, id2, similarity))\n",
    "    return emitted_results\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def my_reduce2(map_results, threshold):\n",
    "    emitted_results = []\n",
    "    for item in map_results.collect():\n",
    "        t = item[0]\n",
    "        print(\"TERM: \", t)\n",
    "        doc_id, document = item[1]\n",
    "        for index, (id1, d1) in enumerate(document):\n",
    "            print(\"ID1 \",id1)\n",
    "            print(\"DOC1 \", d1)\n",
    "            for index2, (id2, d2) in enumerate(document[index+1:], start=index+1):\n",
    "                print(\"ID2 \",id2)\n",
    "                print(\"DOC2 \", d2)\n",
    "                print(\"------------\")\n",
    "                if isinstance(d1, dict) and isinstance(d2, dict):  # Check if d1 and d2 are dictionaries\n",
    "                    print(\"?\")\n",
    "                    if t == max(set(d1.keys()) & set(d2.keys())):\n",
    "                        print(\"T \", t)\n",
    "                        similarity = sim(list(d1.values()), list(d2.values()))\n",
    "                        print(\"sim: \",similarity)\n",
    "                        if similarity >= threshold:\n",
    "                            emitted_results.append((id1, id2, similarity))\n",
    "    return emitted_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cb8d1527",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'all_rows_values_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_14524\\3990998405.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mmap_results_raw\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mall_rows_values_list\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;31m# Creazione dell'RDD\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mrdd_map_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mspark\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msparkContext\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mparallelize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmap_results_raw\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'all_rows_values_list' is not defined"
     ]
    }
   ],
   "source": [
    "map_results_raw = all_rows_values_list\n",
    "\n",
    "\n",
    "# Creazione dell'RDD\n",
    "rdd_map_results = spark.sparkContext.parallelize(map_results_raw)\n",
    "\n",
    "# Esecuzione della mappatura\n",
    "map_results = rdd_map_results.flatMap(lambda x: my_map(x[0], x[1]))\n",
    "print(map_results.collect())\n",
    "# Esecuzione della riduzione\n",
    "threshold = 0.1\n",
    "#reduce_results = map_results.flatMap(lambda x: my_reduce1(x[1], threshold))\n",
    "\n",
    "# Stampa dei risultati\n",
    "#reduce_results.collect()\n",
    "\n",
    "\n",
    "# Chiusura della sessione Spark\n",
    "#spark.stop()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ddb128e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "ris = my_reduce2(map_results, threshold)\n",
    "ris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16b5ce43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all_row_values_tfidf(tfidf_matrix):\n",
    "    num_docs = tfidf_matrix.shape[0]\n",
    "    row_values_list = []\n",
    "    for doc_id in range(num_docs):\n",
    "        row_array = tfidf_matrix.toarray()[doc_id]\n",
    "        row_values = [(index, value) for (index, value) in enumerate(row_array) if value != 0.0]\n",
    "        row_values_list.append((doc_id, row_values))\n",
    "    return row_values_list\n",
    "\n",
    "\n",
    "all_rows_values_list = get_all_row_values_tfidf(tfidf_matrix_docs)\n",
    "#all_rows_values_list"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
