{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6f97c1cc",
   "metadata": {},
   "source": [
    "# Documents Similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3618ccc2",
   "metadata": {},
   "source": [
    "## Read Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4145dd03",
   "metadata": {},
   "outputs": [],
   "source": [
    "#path_name_documents = './Databases/prova/prova50.jsonl'\n",
    "#path_name_documents = './Databases/prova/prova30000.jsonl'\n",
    "path_name_documents = './Databases/prova/prova2000.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "07b4bfe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import string\n",
    "\n",
    "def readFile(path_name):\n",
    "    # Load the JSONL file into a list\n",
    "    with open(path_name, 'r') as f:\n",
    "        lines = f.readlines()\n",
    "\n",
    "    # Convert each JSON object into a dictionary\n",
    "    dicts = [json.loads(line) for line in lines]\n",
    "\n",
    "    # Convert the dictionaries into arrays and stack them vertically\n",
    "    arrays = np.vstack([np.array(list(d.values())) for d in dicts])\n",
    "\n",
    "    # Convert the arrays into a list of lists\n",
    "    text = arrays.tolist()\n",
    "    \n",
    "    return text\n",
    "\n",
    "documents = readFile(path_name_documents)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d4f5b47a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "\n",
    "def time_it(func):\n",
    "    def wrapper(*args, **kwargs):\n",
    "        start_time = time.time()\n",
    "        result = func(*args, **kwargs)\n",
    "        end_time = time.time()\n",
    "        print(f\"Execution time: {end_time - start_time:.5f} seconds\")\n",
    "        return result\n",
    "    return wrapper"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa45c87e",
   "metadata": {},
   "source": [
    "## Tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2a147620",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import nltk\n",
    "import re\n",
    "import string\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer, WordNetLemmatizer\n",
    "\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def stemmingLemming(filtered_tokens):\n",
    "    stemmer = PorterStemmer()\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "    # Perform stemming or lemmatization on filtered tokens\n",
    "    \n",
    "    filtered_tokens = [lemmatizer.lemmatize(token) for token in filtered_tokens]\n",
    "    filtered_tokens = [stemmer.stem(token) for token in filtered_tokens]\n",
    "\n",
    "    return filtered_tokens\n",
    "    \n",
    " \n",
    "    \n",
    "\n",
    "def tokenize(path_name):\n",
    "    \n",
    "    with open(path_name, \"r\") as f:\n",
    "        data = f.readlines()\n",
    "\n",
    "        # Create an empty list to store the tokenized documents\n",
    "        tokenized_docs = []\n",
    "\n",
    "        # Loop through each line in the JSONL file\n",
    "        for line in data:\n",
    "            # Parse the JSON string into a Python dictionary\n",
    "            doc = json.loads(line)\n",
    "\n",
    "            # Extract the text from the dictionary\n",
    "            text = doc['text']\n",
    "            text = text.lower()  # Convert to lowercase\n",
    "            #text = re.sub(r'\\d+', '', text)  # Remove all numbers\n",
    "            text = text.translate(str.maketrans('', '', string.punctuation))  # Remove all punctuation\n",
    "\n",
    "            # Tokenize the text using NLTK\n",
    "            tokens = word_tokenize(text)\n",
    "            tokensStemLem = stemmingLemming(tokens)\n",
    "\n",
    "            # Add the tokenized document to the list\n",
    "            tokenized_docs.append(tokensStemLem)\n",
    "\n",
    "        # Print the tokenized documents\n",
    "    return tokenized_docs\n",
    "\n",
    "\n",
    "tokenized_docs = tokenize(path_name_documents)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96d0ad69",
   "metadata": {},
   "source": [
    "# Sparse Vectors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43553d58",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a261c20e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "\n",
    "def calculateTFIDF(tokenized_docs):\n",
    "    \n",
    "    vectorizer = TfidfVectorizer()\n",
    "    # Fit and transform the tokenized documents into a TF-IDF matrix\n",
    "    tfidf_matrix = vectorizer.fit_transform([' '.join(doc) for doc in tokenized_docs])\n",
    "\n",
    "    # Get the feature names (tokens)\n",
    "    feature_names = vectorizer.get_feature_names_out()\n",
    "\n",
    "    # Return the TF-IDF matrix and the feature names\n",
    "    return tfidf_matrix, feature_names,vectorizer\n",
    "    \n",
    "        \n",
    "\n",
    "tfidf_matrix_docs, feature_names_docs,vectorizer  = calculateTFIDF(tokenized_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ce68baf",
   "metadata": {},
   "source": [
    "## Cosine Similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b11ef999",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Doc 1</th>\n",
       "      <th>Doc 2</th>\n",
       "      <th>Doc 3</th>\n",
       "      <th>Doc 4</th>\n",
       "      <th>Doc 5</th>\n",
       "      <th>Doc 6</th>\n",
       "      <th>Doc 7</th>\n",
       "      <th>Doc 8</th>\n",
       "      <th>Doc 9</th>\n",
       "      <th>Doc 10</th>\n",
       "      <th>...</th>\n",
       "      <th>Doc 1991</th>\n",
       "      <th>Doc 1992</th>\n",
       "      <th>Doc 1993</th>\n",
       "      <th>Doc 1994</th>\n",
       "      <th>Doc 1995</th>\n",
       "      <th>Doc 1996</th>\n",
       "      <th>Doc 1997</th>\n",
       "      <th>Doc 1998</th>\n",
       "      <th>Doc 1999</th>\n",
       "      <th>Doc 2000</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Doc 1</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.088140</td>\n",
       "      <td>0.076180</td>\n",
       "      <td>0.041710</td>\n",
       "      <td>0.135476</td>\n",
       "      <td>0.037048</td>\n",
       "      <td>0.079712</td>\n",
       "      <td>0.083859</td>\n",
       "      <td>0.046190</td>\n",
       "      <td>0.066090</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052495</td>\n",
       "      <td>0.091297</td>\n",
       "      <td>0.074900</td>\n",
       "      <td>0.077853</td>\n",
       "      <td>0.055493</td>\n",
       "      <td>0.056206</td>\n",
       "      <td>0.155063</td>\n",
       "      <td>0.047254</td>\n",
       "      <td>0.098762</td>\n",
       "      <td>0.059326</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc 2</th>\n",
       "      <td>0.088140</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.216128</td>\n",
       "      <td>0.149980</td>\n",
       "      <td>0.125037</td>\n",
       "      <td>0.082548</td>\n",
       "      <td>0.081243</td>\n",
       "      <td>0.109634</td>\n",
       "      <td>0.165225</td>\n",
       "      <td>0.113318</td>\n",
       "      <td>...</td>\n",
       "      <td>0.136774</td>\n",
       "      <td>0.053780</td>\n",
       "      <td>0.086105</td>\n",
       "      <td>0.117846</td>\n",
       "      <td>0.103599</td>\n",
       "      <td>0.098679</td>\n",
       "      <td>0.084447</td>\n",
       "      <td>0.076612</td>\n",
       "      <td>0.107566</td>\n",
       "      <td>0.091730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc 3</th>\n",
       "      <td>0.076180</td>\n",
       "      <td>0.216128</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.112982</td>\n",
       "      <td>0.164268</td>\n",
       "      <td>0.056795</td>\n",
       "      <td>0.076408</td>\n",
       "      <td>0.092951</td>\n",
       "      <td>0.092219</td>\n",
       "      <td>0.082467</td>\n",
       "      <td>...</td>\n",
       "      <td>0.088033</td>\n",
       "      <td>0.051083</td>\n",
       "      <td>0.078266</td>\n",
       "      <td>0.097425</td>\n",
       "      <td>0.101088</td>\n",
       "      <td>0.104249</td>\n",
       "      <td>0.106681</td>\n",
       "      <td>0.069464</td>\n",
       "      <td>0.115833</td>\n",
       "      <td>0.086805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc 4</th>\n",
       "      <td>0.041710</td>\n",
       "      <td>0.149980</td>\n",
       "      <td>0.112982</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.063064</td>\n",
       "      <td>0.033588</td>\n",
       "      <td>0.038800</td>\n",
       "      <td>0.051888</td>\n",
       "      <td>0.088788</td>\n",
       "      <td>0.060705</td>\n",
       "      <td>...</td>\n",
       "      <td>0.094869</td>\n",
       "      <td>0.032597</td>\n",
       "      <td>0.046291</td>\n",
       "      <td>0.042923</td>\n",
       "      <td>0.047268</td>\n",
       "      <td>0.044550</td>\n",
       "      <td>0.043281</td>\n",
       "      <td>0.057974</td>\n",
       "      <td>0.074586</td>\n",
       "      <td>0.058088</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc 5</th>\n",
       "      <td>0.135476</td>\n",
       "      <td>0.125037</td>\n",
       "      <td>0.164268</td>\n",
       "      <td>0.063064</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.057647</td>\n",
       "      <td>0.097862</td>\n",
       "      <td>0.090730</td>\n",
       "      <td>0.087590</td>\n",
       "      <td>0.084105</td>\n",
       "      <td>...</td>\n",
       "      <td>0.101804</td>\n",
       "      <td>0.060967</td>\n",
       "      <td>0.101729</td>\n",
       "      <td>0.085532</td>\n",
       "      <td>0.103503</td>\n",
       "      <td>0.093017</td>\n",
       "      <td>0.073879</td>\n",
       "      <td>0.071080</td>\n",
       "      <td>0.152637</td>\n",
       "      <td>0.081881</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc 1996</th>\n",
       "      <td>0.056206</td>\n",
       "      <td>0.098679</td>\n",
       "      <td>0.104249</td>\n",
       "      <td>0.044550</td>\n",
       "      <td>0.093017</td>\n",
       "      <td>0.050826</td>\n",
       "      <td>0.054918</td>\n",
       "      <td>0.069194</td>\n",
       "      <td>0.051968</td>\n",
       "      <td>0.064365</td>\n",
       "      <td>...</td>\n",
       "      <td>0.058417</td>\n",
       "      <td>0.054911</td>\n",
       "      <td>0.065844</td>\n",
       "      <td>0.067180</td>\n",
       "      <td>0.158831</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.065041</td>\n",
       "      <td>0.064478</td>\n",
       "      <td>0.089159</td>\n",
       "      <td>0.082480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc 1997</th>\n",
       "      <td>0.155063</td>\n",
       "      <td>0.084447</td>\n",
       "      <td>0.106681</td>\n",
       "      <td>0.043281</td>\n",
       "      <td>0.073879</td>\n",
       "      <td>0.040495</td>\n",
       "      <td>0.064603</td>\n",
       "      <td>0.072925</td>\n",
       "      <td>0.048578</td>\n",
       "      <td>0.068262</td>\n",
       "      <td>...</td>\n",
       "      <td>0.052454</td>\n",
       "      <td>0.066905</td>\n",
       "      <td>0.070492</td>\n",
       "      <td>0.057624</td>\n",
       "      <td>0.063972</td>\n",
       "      <td>0.065041</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.050453</td>\n",
       "      <td>0.091349</td>\n",
       "      <td>0.063624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc 1998</th>\n",
       "      <td>0.047254</td>\n",
       "      <td>0.076612</td>\n",
       "      <td>0.069464</td>\n",
       "      <td>0.057974</td>\n",
       "      <td>0.071080</td>\n",
       "      <td>0.048398</td>\n",
       "      <td>0.043551</td>\n",
       "      <td>0.061967</td>\n",
       "      <td>0.047952</td>\n",
       "      <td>0.049643</td>\n",
       "      <td>...</td>\n",
       "      <td>0.055534</td>\n",
       "      <td>0.038722</td>\n",
       "      <td>0.048710</td>\n",
       "      <td>0.054898</td>\n",
       "      <td>0.062131</td>\n",
       "      <td>0.064478</td>\n",
       "      <td>0.050453</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.099591</td>\n",
       "      <td>0.050479</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc 1999</th>\n",
       "      <td>0.098762</td>\n",
       "      <td>0.107566</td>\n",
       "      <td>0.115833</td>\n",
       "      <td>0.074586</td>\n",
       "      <td>0.152637</td>\n",
       "      <td>0.153502</td>\n",
       "      <td>0.071356</td>\n",
       "      <td>0.092917</td>\n",
       "      <td>0.074554</td>\n",
       "      <td>0.097069</td>\n",
       "      <td>...</td>\n",
       "      <td>0.085829</td>\n",
       "      <td>0.070660</td>\n",
       "      <td>0.104924</td>\n",
       "      <td>0.115240</td>\n",
       "      <td>0.085430</td>\n",
       "      <td>0.089159</td>\n",
       "      <td>0.091349</td>\n",
       "      <td>0.099591</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.091079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Doc 2000</th>\n",
       "      <td>0.059326</td>\n",
       "      <td>0.091730</td>\n",
       "      <td>0.086805</td>\n",
       "      <td>0.058088</td>\n",
       "      <td>0.081881</td>\n",
       "      <td>0.042441</td>\n",
       "      <td>0.043895</td>\n",
       "      <td>0.089061</td>\n",
       "      <td>0.057945</td>\n",
       "      <td>0.063727</td>\n",
       "      <td>...</td>\n",
       "      <td>0.060879</td>\n",
       "      <td>0.034718</td>\n",
       "      <td>0.047548</td>\n",
       "      <td>0.067888</td>\n",
       "      <td>0.089461</td>\n",
       "      <td>0.082480</td>\n",
       "      <td>0.063624</td>\n",
       "      <td>0.050479</td>\n",
       "      <td>0.091079</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 2000 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Doc 1     Doc 2     Doc 3     Doc 4     Doc 5     Doc 6  \\\n",
       "Doc 1     1.000000  0.088140  0.076180  0.041710  0.135476  0.037048   \n",
       "Doc 2     0.088140  1.000000  0.216128  0.149980  0.125037  0.082548   \n",
       "Doc 3     0.076180  0.216128  1.000000  0.112982  0.164268  0.056795   \n",
       "Doc 4     0.041710  0.149980  0.112982  1.000000  0.063064  0.033588   \n",
       "Doc 5     0.135476  0.125037  0.164268  0.063064  1.000000  0.057647   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "Doc 1996  0.056206  0.098679  0.104249  0.044550  0.093017  0.050826   \n",
       "Doc 1997  0.155063  0.084447  0.106681  0.043281  0.073879  0.040495   \n",
       "Doc 1998  0.047254  0.076612  0.069464  0.057974  0.071080  0.048398   \n",
       "Doc 1999  0.098762  0.107566  0.115833  0.074586  0.152637  0.153502   \n",
       "Doc 2000  0.059326  0.091730  0.086805  0.058088  0.081881  0.042441   \n",
       "\n",
       "             Doc 7     Doc 8     Doc 9    Doc 10  ...  Doc 1991  Doc 1992  \\\n",
       "Doc 1     0.079712  0.083859  0.046190  0.066090  ...  0.052495  0.091297   \n",
       "Doc 2     0.081243  0.109634  0.165225  0.113318  ...  0.136774  0.053780   \n",
       "Doc 3     0.076408  0.092951  0.092219  0.082467  ...  0.088033  0.051083   \n",
       "Doc 4     0.038800  0.051888  0.088788  0.060705  ...  0.094869  0.032597   \n",
       "Doc 5     0.097862  0.090730  0.087590  0.084105  ...  0.101804  0.060967   \n",
       "...            ...       ...       ...       ...  ...       ...       ...   \n",
       "Doc 1996  0.054918  0.069194  0.051968  0.064365  ...  0.058417  0.054911   \n",
       "Doc 1997  0.064603  0.072925  0.048578  0.068262  ...  0.052454  0.066905   \n",
       "Doc 1998  0.043551  0.061967  0.047952  0.049643  ...  0.055534  0.038722   \n",
       "Doc 1999  0.071356  0.092917  0.074554  0.097069  ...  0.085829  0.070660   \n",
       "Doc 2000  0.043895  0.089061  0.057945  0.063727  ...  0.060879  0.034718   \n",
       "\n",
       "          Doc 1993  Doc 1994  Doc 1995  Doc 1996  Doc 1997  Doc 1998  \\\n",
       "Doc 1     0.074900  0.077853  0.055493  0.056206  0.155063  0.047254   \n",
       "Doc 2     0.086105  0.117846  0.103599  0.098679  0.084447  0.076612   \n",
       "Doc 3     0.078266  0.097425  0.101088  0.104249  0.106681  0.069464   \n",
       "Doc 4     0.046291  0.042923  0.047268  0.044550  0.043281  0.057974   \n",
       "Doc 5     0.101729  0.085532  0.103503  0.093017  0.073879  0.071080   \n",
       "...            ...       ...       ...       ...       ...       ...   \n",
       "Doc 1996  0.065844  0.067180  0.158831  1.000000  0.065041  0.064478   \n",
       "Doc 1997  0.070492  0.057624  0.063972  0.065041  1.000000  0.050453   \n",
       "Doc 1998  0.048710  0.054898  0.062131  0.064478  0.050453  1.000000   \n",
       "Doc 1999  0.104924  0.115240  0.085430  0.089159  0.091349  0.099591   \n",
       "Doc 2000  0.047548  0.067888  0.089461  0.082480  0.063624  0.050479   \n",
       "\n",
       "          Doc 1999  Doc 2000  \n",
       "Doc 1     0.098762  0.059326  \n",
       "Doc 2     0.107566  0.091730  \n",
       "Doc 3     0.115833  0.086805  \n",
       "Doc 4     0.074586  0.058088  \n",
       "Doc 5     0.152637  0.081881  \n",
       "...            ...       ...  \n",
       "Doc 1996  0.089159  0.082480  \n",
       "Doc 1997  0.091349  0.063624  \n",
       "Doc 1998  0.099591  0.050479  \n",
       "Doc 1999  1.000000  0.091079  \n",
       "Doc 2000  0.091079  1.000000  \n",
       "\n",
       "[2000 rows x 2000 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "def similarity(tfidf_matrix):\n",
    "    # calcoliamo la cosine similarity tra i documenti\n",
    "    cos_sim = cosine_similarity(tfidf_matrix)\n",
    "\n",
    "    # creiamo una tabella con le cosine similarity per ogni coppia di documenti\n",
    "    sim_table = pd.DataFrame(cos_sim, columns=['Doc ' + str(i+1) for i in range(cos_sim.shape[0])], index=['Doc ' + str(i+1) for i in range(cos_sim.shape[0])])\n",
    "    \n",
    "    return sim_table, cos_sim\n",
    "\n",
    "cos_sim_table, cos_sim = similarity(tfidf_matrix_docs)\n",
    "cos_sim_table\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5873dd86",
   "metadata": {},
   "source": [
    "## For each document calculate the number of documents with a certain thresholds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fa200ca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 0.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8ef266d",
   "metadata": {},
   "source": [
    "### Sequential Algoritghm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "33f1ff04",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.33099 seconds\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "@time_it\n",
    "def sequential_pair_similar_documents(cos_sim, threshold):   \n",
    "    # Creiamo una lista di coppie di documenti simili con un valore di similarità superiore al threshold\n",
    "    sim_pairs = []\n",
    "    n_docs = cos_sim.shape[0]\n",
    "    for i in range(n_docs):\n",
    "        for j in range(i+1, n_docs):\n",
    "            if cos_sim[i,j] > threshold:\n",
    "                sim_pairs.append((i+1, j+1))\n",
    "            \n",
    "    return sim_pairs\n",
    "\n",
    "\n",
    "sim_pairs = sequential_pair_similar_documents(cos_sim, threshold)\n",
    "#print(sim_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f37df90e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.33500 seconds\n"
     ]
    }
   ],
   "source": [
    "@time_it\n",
    "def sequential_count_similar_documents(cos_sim, threshold):\n",
    "    num_similar = []\n",
    "    n_docs = cos_sim.shape[0]\n",
    "    for i in range(n_docs):\n",
    "        num = 0\n",
    "        for j in range(i+1, n_docs):\n",
    "            if cos_sim[i,j] > threshold:\n",
    "                num += 1\n",
    "        num_similar.append(num)\n",
    "    return num_similar, threshold\n",
    "\n",
    "num_similar, threshold = sequential_count_similar_documents(cos_sim, threshold)\n",
    "#print(num_similar)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "58891ae8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Execution time: 0.33700 seconds\n"
     ]
    }
   ],
   "source": [
    "@time_it\n",
    "def sequential_similar_documents(cos_sim, threshold):\n",
    "    similar_docs = []\n",
    "    n_docs = cos_sim.shape[0]\n",
    "    for i in range(n_docs):\n",
    "        sim_docs = []\n",
    "        for j in range(i+1, n_docs):\n",
    "            if cos_sim[i,j] > threshold:\n",
    "                sim_docs.append(f\"Doc {j+1}\")\n",
    "        similar_docs.append(sim_docs)\n",
    "    return similar_docs\n",
    "similar_docs = sequential_similar_documents(cos_sim, threshold)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1a22b7bf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Documents</th>\n",
       "      <th>Number of similar documents</th>\n",
       "      <th>Similar Documents</th>\n",
       "      <th>Threshold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Doc 1</td>\n",
       "      <td>42</td>\n",
       "      <td>Doc 80, Doc 214, Doc 339, Doc 365, Doc 416, Do...</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Doc 2</td>\n",
       "      <td>16</td>\n",
       "      <td>Doc 3, Doc 147, Doc 162, Doc 182, Doc 253, Doc...</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Doc 3</td>\n",
       "      <td>7</td>\n",
       "      <td>Doc 162, Doc 174, Doc 182, Doc 487, Doc 683, D...</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Doc 4</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Doc 5</td>\n",
       "      <td>14</td>\n",
       "      <td>Doc 16, Doc 98, Doc 162, Doc 458, Doc 558, Doc...</td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1995</th>\n",
       "      <td>Doc 1996</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1996</th>\n",
       "      <td>Doc 1997</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1997</th>\n",
       "      <td>Doc 1998</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>Doc 1999</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1999</th>\n",
       "      <td>Doc 2000</td>\n",
       "      <td>0</td>\n",
       "      <td></td>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Documents  Number of similar documents  \\\n",
       "0        Doc 1                           42   \n",
       "1        Doc 2                           16   \n",
       "2        Doc 3                            7   \n",
       "3        Doc 4                            0   \n",
       "4        Doc 5                           14   \n",
       "...        ...                          ...   \n",
       "1995  Doc 1996                            0   \n",
       "1996  Doc 1997                            0   \n",
       "1997  Doc 1998                            0   \n",
       "1998  Doc 1999                            0   \n",
       "1999  Doc 2000                            0   \n",
       "\n",
       "                                      Similar Documents  Threshold  \n",
       "0     Doc 80, Doc 214, Doc 339, Doc 365, Doc 416, Do...        0.2  \n",
       "1     Doc 3, Doc 147, Doc 162, Doc 182, Doc 253, Doc...        0.2  \n",
       "2     Doc 162, Doc 174, Doc 182, Doc 487, Doc 683, D...        0.2  \n",
       "3                                                              0.2  \n",
       "4     Doc 16, Doc 98, Doc 162, Doc 458, Doc 558, Doc...        0.2  \n",
       "...                                                 ...        ...  \n",
       "1995                                                           0.2  \n",
       "1996                                                           0.2  \n",
       "1997                                                           0.2  \n",
       "1998                                                           0.2  \n",
       "1999                                                           0.2  \n",
       "\n",
       "[2000 rows x 4 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def create_similar_table(similar_docs, num_similar, threshold):\n",
    "    doc_names = [f\"Doc {i+1}\" for i in range(len(num_similar))]\n",
    "    similar_docs_str = [\", \".join(docs) for docs in similar_docs]\n",
    "    similar_table = pd.DataFrame({\"Documents\": doc_names, \"Number of similar documents\": num_similar, \"Similar Documents\": similar_docs_str, \"Threshold\": threshold})\n",
    "    return similar_table\n",
    "\n",
    "similar_table = create_similar_table(similar_docs, num_similar, threshold)\n",
    "similar_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ced0fa39",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "2900c4d6",
   "metadata": {},
   "source": [
    "# Prove Clustering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "280d84a8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lita4\\AppData\\Local\\Temp\\ipykernel_11796\\3280178790.py:10: FutureWarning: iteritems is deprecated and will be removed in a future version. Use .items instead.\n",
      "  for j, sim in row.iteritems():\n"
     ]
    }
   ],
   "source": [
    "def divide_documents(cos_sim_table, threshold):\n",
    "    # Creiamo un dizionario per i cluster\n",
    "    clusters = {}\n",
    "    # Creiamo un set per tenere traccia dei documenti già assegnati a un cluster\n",
    "    assigned_docs = set()\n",
    "    # Iteriamo su ogni riga e colonna della tabella di similarità\n",
    "    for i, row in cos_sim_table.iterrows():\n",
    "        if i not in assigned_docs:  # Se il documento non è già stato assegnato a un cluster\n",
    "            cluster = []  # Creiamo un nuovo cluster\n",
    "            for j, sim in row.iteritems():\n",
    "                if j != i and j not in assigned_docs and sim >= threshold:  # Se il documento non è già stato assegnato a un cluster, non è se stesso e ha una similarità maggiore o uguale alla soglia\n",
    "                    cluster.append(j)  # Aggiungiamo il documento al cluster\n",
    "                    assigned_docs.add(j)  # Segniamo il documento come assegnato\n",
    "            cluster.append(i)  # Aggiungiamo il documento corrente al cluster\n",
    "            assigned_docs.add(i)  # Segniamo il documento corrente come assegnato\n",
    "            clusters[f'Cluster {len(clusters)+1}'] = cluster  # Aggiungiamo il cluster al dizionario di cluster\n",
    "    return clusters\n",
    "\n",
    "\n",
    "clusters = divide_documents(cos_sim_table, 0.2)\n",
    "#clusters\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29991013",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "d0fa1e27",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42\n"
     ]
    }
   ],
   "source": [
    "def find_similar_documents(cos_sim_table, doc_name, similarity_threshold):\n",
    "    # trova il vettore di similarità del documento specificato\n",
    "    doc_sim_vector = cos_sim_table[doc_name]\n",
    "\n",
    "    # trova il numero di documenti che hanno una similarità superiore alla soglia specificata\n",
    "    similar_docs_count = len([similarity for similarity in doc_sim_vector if similarity > similarity_threshold])\n",
    "\n",
    "    return similar_docs_count\n",
    "\n",
    "similar_docs_count = find_similar_documents(cos_sim_table, 'Doc 1', 0.2)\n",
    "print(similar_docs_count-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8272e79",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3cd7de62",
   "metadata": {},
   "source": [
    "# Parallel Alghoritm "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "06ff0826",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['PYSPARK_PYTHON'] = 'C:/Users/lita4/anaconda3/python.exe'\n",
    "os.environ['PYSPARK_DRIVER_PYTHON'] = 'C:/Users/lita4/anaconda3/python.exe'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ee9756d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "\n",
    "#spark = SparkSession.builder.appName(\"document-similarity\").getOrCreate()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "b9d58896",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_name_documents = './Databases/prova/prova50.jsonl'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b6a1315",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "0c9cc5eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#conf = SparkConf().setAppName(\"MyApp\")\n",
    "#sc = SparkContext(conf=conf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "11f8274e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "from pyspark.ml.linalg import SparseVector, DenseVector\n",
    "from itertools import combinations\n",
    "import json\n",
    "\n",
    "\n",
    "def load_documents(spark, input_path):\n",
    "    \"\"\"\n",
    "    Carica i documenti dal file JSONL e restituisce un RDD di Spark.\n",
    "    Il file JSONL deve contenere un documento per riga.\n",
    "    \"\"\"\n",
    "\n",
    "\n",
    "    # Leggi il file JSONL come RDD di Spark\n",
    "    rdd = spark.sparkContext.textFile(input_path)\n",
    "\n",
    "    \n",
    "    # Estrai l'id e il testo di ogni documento\n",
    "    documents = rdd.map(lambda line: json.loads(line)).map(lambda d: (d[\"_id\"], d[\"text\"]))\n",
    "    return documents\n",
    "\n",
    "#documents = load_documents(spark, path_name_documents)\n",
    "#documents_list = documents.collect()\n",
    "#print(documents_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdba7c51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4fa506bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import HashingTF, IDF\n",
    "from pyspark.ml.linalg import SparseVector, DenseVector\n",
    "from itertools import combinations\n",
    "import json\n",
    "\n",
    "\n",
    "def preprocess_document(document, hashingTF, idfModel):\n",
    "    \"\"\"\n",
    "    Applica la pre-elaborazione a un singolo documento, includendo la rappresentazione HashingTF\n",
    "    e la rappresentazione IDF.\n",
    "    Restituisce un oggetto DenseVector che rappresenta il documento.\n",
    "    \"\"\"\n",
    "\n",
    "    # Estra il testo dal documento\n",
    "    text = document[1]\n",
    "\n",
    "    # Crea una lista di tuple (indice, valore) per ogni parola nel testo\n",
    "    word_counts = hashingTF.transform(text.split())\n",
    "    word_tfidf = idfModel.transform(word_counts)\n",
    "    words = [(i, v) for i, v in enumerate(word_tfidf.toArray()) if v != 0.0]\n",
    "\n",
    "    # Crea un oggetto SparseVector che rappresenta il documento\n",
    "    if len(words) == 0:\n",
    "        return None\n",
    "    else:\n",
    "        return DenseVector([v for i, v in words])\n",
    "\n",
    "def calculate_similarity(documents):\n",
    "    \"\"\"\n",
    "    Calcola la cosine similarity tra tutte le coppie di documenti.\n",
    "    Restituisce un RDD di tuple (id_doc_1, id_doc_2, cosine_similarity).\n",
    "    \"\"\"\n",
    "\n",
    "    # Calcola la cosine similarity tra tutte le coppie di documenti\n",
    "    document_pairs = combinations(documents.collect(), 2)\n",
    "    similarities = []\n",
    "    for doc1, doc2 in document_pairs:\n",
    "        if doc1 is not None and doc2 is not None:\n",
    "            cosine_sim = doc1.dot(doc2) / (doc1.norm(2) * doc2.norm(2))\n",
    "            similarities.append((doc1[0], doc2[0], cosine_sim))\n",
    "\n",
    "    return similarities\n",
    "\n",
    "\n",
    "def main():\n",
    "\n",
    "    # Carica i documenti dal file JSONL\n",
    "    documents = load_documents(spark, path_name_documents)\n",
    "\n",
    "    # Crea un oggetto HashingTF per la rappresentazione dei documenti come bag of words\n",
    "    hashingTF = HashingTF(numFeatures=10000, inputCol=\"text\", outputCol=\"word_count\")\n",
    "\n",
    "    # Calcola la rappresentazione IDF dei documenti\n",
    "    word_counts = hashingTF.transform(documents)\n",
    "    idf = IDF(inputCol=\"word_count\", outputCol=\"features\")\n",
    "    idfModel = idf.fit(word_counts)\n",
    "\n",
    "    # Pre-elabora tutti i documenti\n",
    "    preprocessed_documents = documents.map(lambda d: (d[0], preprocess_document(d, hashingTF, idfModel))) \\\n",
    "                                       .filter(lambda d: d[1] is not None)\n",
    "\n",
    "    # Calcola la cosine similarity tra tutte le coppie di documenti\n",
    "    similarities = calculate_similarity(preprocessed_documents)\n",
    "\n",
    "\n",
    "\n",
    "#main()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ed0072f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f6f7bd5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a68ffaa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkConf\n",
    "from pyspark import SparkContext\n",
    "\n",
    "import os\n",
    "\n",
    "def fu():\n",
    "    os.environ['PYSPARK_PYTHON'] = 'C:/Users/lita4/anaconda3/python.exe'\n",
    "    os.environ['PYSPARK_DRIVER_PYTHON'] = 'C:/Users/lita4/anaconda3/python.exe'\n",
    "\n",
    "    conf = SparkConf().setAppName(\"MyApp\")\n",
    "    sc = SparkContext(conf=conf)\n",
    "\n",
    "\n",
    "    def sq(x):\n",
    "        return x*x\n",
    "\n",
    "    data = [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19]\n",
    "    myrdd = sc.parallelize(data)\n",
    "    squared = myrdd.map(sq) # this creates a new RDD\n",
    "    print(squared.collect()) # careful: collect() is an action"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3fefe51",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
